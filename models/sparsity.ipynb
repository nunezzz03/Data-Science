{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HItPcnC1Smiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3970552e-3668-45fa-b2dc-c39a648906e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GLRZ89TcGswN"
      },
      "outputs": [],
      "source": [
        "from numpy import ndarray\n",
        "from pandas import read_csv, DataFrame\n",
        "from matplotlib.figure import Figure\n",
        "from matplotlib.pyplot import subplots, savefig, figure, close\n",
        "from seaborn import heatmap\n",
        "from dslabs_functions import HEIGHT, plot_multi_scatters_chart, get_variable_types\n",
        "from itertools import combinations\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [\n",
        "    {\"file_tag\": \"accidents\", \"filename\": \"drive/MyDrive/traffic_accidents_.csv\", \"target\": \"crash_type\"},\n",
        "    {\"file_tag\": \"flights\", \"filename\": \"drive/MyDrive/Combined_Flights_2022.csv\", \"target\": \"ArrDel15\"},\n",
        "]"
      ],
      "metadata": {
        "id": "saL6NhUhslnO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(a, n):\n",
        "    k, m = divmod(len(a), n)\n",
        "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))"
      ],
      "metadata": {
        "id": "KAqdGYJiztxF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CORRELATION MATRIX FOR ACCIDENTS"
      ],
      "metadata": {
        "id": "D8ra9BpLxowi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets[0]\n",
        "\n",
        "file_tag = dataset[\"file_tag\"]\n",
        "filename = dataset[\"filename\"]\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "print(f\"\\nProcessing: {file_tag.upper()}\")\n",
        "\n",
        "# Load and clean data\n",
        "data: DataFrame = read_csv(filename, na_values=\"\")\n",
        "print(f\"   Loaded {len(data)} records\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"   After dropping NA: {len(data)} records\")\n",
        "\n",
        "# Sample if dataset is large (for performance)\n",
        "# if len(data) > 5000:\n",
        "data.sample(frac=0.25, random_state=42)\n",
        "print(f\"   Sampled to {len(data)} records for performance\")\n",
        "\n",
        "vars: list = data.columns.to_list()\n",
        "\n",
        "if len(vars) == 0:\n",
        "    print(f\"   No numeric variables found, skipping {file_tag}\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Found {len(vars)} numeric variables\")\n",
        "\n",
        "# === PART 0: CORRELATION MATRIX ===\n",
        "\n",
        "print(f\"   Generating correlation matrix...\")\n",
        "variables_types: dict[str, list] = get_variable_types(data)\n",
        "numeric: list[str] = variables_types[\"numeric\"]\n",
        "\n",
        "if len(numeric) > 1:\n",
        "    corr_mtx: DataFrame = data[numeric].corr().abs()\n",
        "\n",
        "    figure()\n",
        "    heatmap(\n",
        "        abs(corr_mtx),\n",
        "        xticklabels=numeric,\n",
        "        yticklabels=numeric,\n",
        "        annot=False,\n",
        "        cmap=\"Blues\",\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "    )\n",
        "    output_path = f\"images/correlation_matrix/{file_tag}_correlation_analysis.png\"\n",
        "    savefig(output_path)\n",
        "    close()\n",
        "    print(f\"   ✓ Saved correlation matrix: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi6vvhiAse2z",
        "outputId": "2dd6fb64-e5bc-4ea0-ab43-c2f6760d5f45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: ACCIDENTS\n",
            "   Loaded 209306 records\n",
            "   After dropping NA: 209306 records\n",
            "   Sampled to 209306 records for performance\n",
            "   Found 24 numeric variables\n",
            "   Generating correlation matrix...\n",
            "   ✓ Saved correlation matrix: images/correlation_matrix/accidents_correlation_analysis.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CORRELATION MATRIX FOR FLIGHTS"
      ],
      "metadata": {
        "id": "GSIXTATPIYEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets[1]\n",
        "\n",
        "file_tag = dataset[\"file_tag\"]\n",
        "filename = dataset[\"filename\"]\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "print(f\"\\nProcessing: {file_tag.upper()}\")\n",
        "\n",
        "# Load and clean data\n",
        "data: DataFrame = read_csv(filename, na_values=\"\")\n",
        "print(f\"   Loaded {len(data)} records\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"   After dropping NA: {len(data)} records\")\n",
        "\n",
        "# Sample if dataset is large (for performance)\n",
        "# if len(data) > 5000:\n",
        "data = data.sample(frac=0.25, random_state=42)\n",
        "print(f\"   Sampled to {len(data)} records for performance\")\n",
        "\n",
        "vars: list = data.columns.to_list()\n",
        "\n",
        "if len(vars) == 0:\n",
        "    print(f\"   No numeric variables found, skipping {file_tag}\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Found {len(vars)} numeric variables\")\n",
        "\n",
        "# === PART 0: CORRELATION MATRIX ===\n",
        "\n",
        "print(f\"   Generating correlation matrix...\")\n",
        "variables_types: dict[str, list] = get_variable_types(data)\n",
        "numeric: list[str] = variables_types[\"numeric\"]\n",
        "\n",
        "if len(numeric) > 1:\n",
        "    corr_mtx: DataFrame = data[numeric].corr().abs()\n",
        "\n",
        "    figure()\n",
        "    heatmap(\n",
        "        abs(corr_mtx),\n",
        "        xticklabels=numeric,\n",
        "        yticklabels=numeric,\n",
        "        annot=False,\n",
        "        cmap=\"Blues\",\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "    )\n",
        "    output_path = f\"images/correlation_matrix/{file_tag}_correlation_analysis.png\"\n",
        "    savefig(output_path)\n",
        "    close()\n",
        "    print(f\"   ✓ Saved correlation matrix: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxaXUT4QxwxM",
        "outputId": "37833740-8382-4eea-a6d1-419defe77a59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: FLIGHTS\n",
            "   Loaded 4078318 records\n",
            "   After dropping NA: 3944916 records\n",
            "   Sampled to 986229 records for performance\n",
            "   Found 61 numeric variables\n",
            "   Generating correlation matrix...\n",
            "   ✓ Saved correlation matrix: images/correlation_matrix/flights_correlation_analysis.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SPARSITY STUDY FOR ACCIDENTS\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HSnZ2KE5JzYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets[0]\n",
        "\n",
        "file_tag = dataset[\"file_tag\"]\n",
        "filename = dataset[\"filename\"]\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "print(f\"\\nProcessing: {file_tag.upper()}\")\n",
        "\n",
        "# Load and clean data\n",
        "data: DataFrame = read_csv(filename, na_values=\"\")\n",
        "print(f\"   Loaded {len(data)} records\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"   After dropping NA: {len(data)} records\")\n",
        "\n",
        "# Sample if dataset is large (for performance)\n",
        "# if len(data) > 5000:\n",
        "data = data.sample(frac=0.25, random_state=42)\n",
        "print(f\"   Sampled to {len(data)} records for performance\")\n",
        "\n",
        "# Get only numeric columns\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "all_vars: list = numeric_data.columns.to_list()\n",
        "\n",
        "if len(all_vars) == 0:\n",
        "    print(f\"   No numeric variables found, skipping {file_tag}\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Found {len(all_vars)} numeric variables\")\n",
        "\n",
        "# === PART 1: SPARSITY STUDY (without class discrimination) ===\n",
        "\n",
        "print(f\"   Generating sparsity study...\")\n",
        "if len(all_vars) > 1:\n",
        "    n: int = len(all_vars)\n",
        "    fig: Figure\n",
        "    axs: ndarray\n",
        "    fig, axs = subplots(n - 1, n - 1, figsize=((n - 1) * HEIGHT, (n - 1) * HEIGHT), squeeze=False)\n",
        "\n",
        "    for i in range(len(all_vars)):\n",
        "        var1: str = all_vars[i]\n",
        "        for j in range(i + 1, len(all_vars)):\n",
        "            var2: str = all_vars[j]\n",
        "            plot_multi_scatters_chart(numeric_data, var1, var2, ax=axs[i, j - 1])\n",
        "\n",
        "    output_path = f\"images/sparsity_study/{file_tag}_sparsity_study.png\"\n",
        "    savefig(output_path)\n",
        "    close()\n",
        "    print(f\"   ✓ Saved sparsity study: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6IVG4VutA2T",
        "outputId": "a04c6bc8-0072-4f89-d143-8476bf63cd3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: ACCIDENTS\n",
            "   Loaded 209306 records\n",
            "   After dropping NA: 209306 records\n",
            "   Sampled to 52326 records for performance\n",
            "   Found 10 numeric variables\n",
            "   Generating sparsity study...\n",
            "   ✓ Saved sparsity study: images/sparsity_study/accidents_sparsity_study.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SPARSITY STUDY FOR FLIGHTS"
      ],
      "metadata": {
        "id": "jZcEMBYaJ8_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets[1]\n",
        "\n",
        "file_tag = dataset[\"file_tag\"]\n",
        "filename = dataset[\"filename\"]\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "print(f\"\\nProcessing: {file_tag.upper()}\")\n",
        "\n",
        "# Load and clean data\n",
        "data: DataFrame = read_csv(filename, na_values=\"\")\n",
        "print(f\"   Loaded {len(data)} records\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"   After dropping NA: {len(data)} records\")\n",
        "\n",
        "# Sample if dataset is large (for performance)\n",
        "# if len(data) > 5000:\n",
        "data = data.sample(frac=0.25, random_state=42)\n",
        "print(f\"   Sampled to {len(data)} records for performance\")\n",
        "\n",
        "vars: list = data.columns.to_list()\n",
        "\n",
        "if len(vars) == 0:\n",
        "    print(f\"   No numeric variables found, skipping {file_tag}\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Found {len(vars)} numeric variables\")\n",
        "\n",
        "# === PART 1: SPARSITY STUDY (without class discrimination) ===\n",
        "\n",
        "print(f\"   Generating sparsity study...\")\n",
        "if len(all_vars) > 1:\n",
        "    n: int = len(all_vars)\n",
        "    fig: Figure\n",
        "    axs: ndarray\n",
        "    fig, axs = subplots(n - 1, n - 1, figsize=((n - 1) * HEIGHT, (n - 1) * HEIGHT), squeeze=False)\n",
        "\n",
        "    for i in range(len(all_vars)):\n",
        "        var1: str = all_vars[i]\n",
        "        for j in range(i + 1, len(all_vars)):\n",
        "            var2: str = all_vars[j]\n",
        "            plot_multi_scatters_chart(numeric_data, var1, var2, ax=axs[i, j - 1])\n",
        "\n",
        "    output_path = f\"images/sparsity_study/{file_tag}_sparsity_study.png\"\n",
        "    savefig(output_path)\n",
        "    close()\n",
        "    print(f\"   ✓ Saved sparsity study: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVzqPEW20LVZ",
        "outputId": "e978f494-c8d0-4166-fc58-1bed8c0dfa41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: FLIGHTS\n",
            "   Loaded 4078318 records\n",
            "   After dropping NA: 3944916 records\n",
            "   Sampled to 986229 records for performance\n",
            "   Found 61 numeric variables\n",
            "   Generating sparsity study...\n",
            "   ✓ Saved sparsity study: images/sparsity_study/flights_sparsity_study.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SPARSITY STUDY PER CLASS FOR ACCIDENTS"
      ],
      "metadata": {
        "id": "0LdSjI3-LyHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets[0]\n",
        "\n",
        "file_tag = dataset[\"file_tag\"]\n",
        "filename = dataset[\"filename\"]\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "print(f\"\\nProcessing: {file_tag.upper()}\")\n",
        "\n",
        "# Load and clean data\n",
        "data: DataFrame = read_csv(filename, na_values=\"\")\n",
        "print(f\"   Loaded {len(data)} records\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"   After dropping NA: {len(data)} records\")\n",
        "\n",
        "# Sample if dataset is large (for performance)\n",
        "# if len(data) > 5000:\n",
        "data = data.sample(frac=0.25, random_state=42)\n",
        "print(f\"   Sampled to {len(data)} records for performance\")\n",
        "\n",
        "vars: list = data.columns.to_list()\n",
        "\n",
        "if len(vars) == 0:\n",
        "    print(f\"   No numeric variables found, skipping {file_tag}\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Found {len(vars)} numeric variables\")\n",
        "\n",
        "# === PART 2: SPARSITY PER CLASS (with class discrimination) ===\n",
        "if target not in data.columns:\n",
        "    print(f\"   Warning: Target '{target}' not found, skipping per-class analysis\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Generating sparsity per class study...\")\n",
        "# Exclude target from variables for per-class analysis\n",
        "vars_no_target: list = [col for col in vars if col != target]\n",
        "\n",
        "vars_no_target_split: list = split(vars_no_target, 4)\n",
        "\n",
        "i = -1\n",
        "\n",
        "for vars_no_target_subset in combinations(vars_no_target_split, 2):\n",
        "  i += 1\n",
        "  print(f\"   Processing subset: {vars_no_target_subset[0]}\")\n",
        "  print(f\"   Processing subset: {vars_no_target_subset[1]}\")\n",
        "  merged_subsets = vars_no_target_subset[0] + vars_no_target_subset[1]\n",
        "  print(f\"   Merged subsets: {merged_subsets}\")\n",
        "\n",
        "  if len(vars_no_target) > 1:\n",
        "      n: int = len(vars_no_target)\n",
        "      fig, axs = subplots(n - 1, n - 1, figsize=((n - 1) * HEIGHT, (n - 1) * HEIGHT), squeeze=False)\n",
        "\n",
        "      for i in range(len(vars_no_target)):\n",
        "          var1: str = vars_no_target[i]\n",
        "          for j in range(i + 1, len(vars_no_target)):\n",
        "              var2: str = vars_no_target[j]\n",
        "              plot_multi_scatters_chart(data, var1, var2, target, ax=axs[i, j - 1])\n",
        "\n",
        "      output_path = f\"images/sparsity_per_class/{file_tag}_sparsity_per_class_study_{i}.png\"\n",
        "      savefig(output_path)\n",
        "      close()\n",
        "      print(f\"   ✓ Saved per-class study: {output_path}\")\n",
        "\n",
        "print(f\"   ✓ Completed {file_tag.upper()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"SPARSITY PROFILING COMPLETE!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoVyA4ysIMZo",
        "outputId": "b53d3afd-e25b-4aaa-f38c-1deea2c2918b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: ACCIDENTS\n",
            "   Loaded 209306 records\n",
            "   After dropping NA: 209306 records\n",
            "   Sampled to 52326 records for performance\n",
            "   Found 24 numeric variables\n",
            "   Generating sparsity per class study...\n",
            "   Processing subset: ['crash_date', 'traffic_control_device', 'weather_condition', 'lighting_condition', 'first_crash_type', 'trafficway_type']\n",
            "   Processing subset: ['alignment', 'roadway_surface_cond', 'road_defect', 'intersection_related_i', 'damage', 'prim_contributory_cause']\n",
            "   Merged subsets: ['crash_date', 'traffic_control_device', 'weather_condition', 'lighting_condition', 'first_crash_type', 'trafficway_type', 'alignment', 'roadway_surface_cond', 'road_defect', 'intersection_related_i', 'damage', 'prim_contributory_cause']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SPARSITY STUDY PER CLASS FOR FLIGHTS"
      ],
      "metadata": {
        "id": "x2rRM48dRjcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets[1]\n",
        "\n",
        "file_tag = dataset[\"file_tag\"]\n",
        "filename = dataset[\"filename\"]\n",
        "target = dataset[\"target\"]\n",
        "\n",
        "print(f\"\\nProcessing: {file_tag.upper()}\")\n",
        "\n",
        "# Load and clean data\n",
        "data: DataFrame = read_csv(filename, na_values=\"\")\n",
        "print(f\"   Loaded {len(data)} records\")\n",
        "\n",
        "data = data.dropna()\n",
        "print(f\"   After dropping NA: {len(data)} records\")\n",
        "\n",
        "# Sample if dataset is large (for performance)\n",
        "# if len(data) > 5000:\n",
        "data = data.sample(fra, random_state=42)\n",
        "print(f\"   Sampled to {len(data)} records for performance\")\n",
        "\n",
        "vars: list = data.columns.to_list()\n",
        "\n",
        "if len(vars) == 0:\n",
        "    print(f\"   No numeric variables found, skipping {file_tag}\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Found {len(vars)} numeric variables\")\n",
        "\n",
        "# === PART 2: SPARSITY PER CLASS (with class discrimination) ===\n",
        "if target not in data.columns:\n",
        "    print(f\"   Warning: Target '{target}' not found, skipping per-class analysis\")\n",
        "    exit\n",
        "\n",
        "print(f\"   Generating sparsity per class study...\")\n",
        "# Exclude target from variables for per-class analysis\n",
        "vars_no_target: list = [col for col in vars if col != target]\n",
        "\n",
        "if len(vars_no_target) > 1:\n",
        "    n: int = len(vars_no_target)\n",
        "    fig, axs = subplots(n - 1, n - 1, figsize=((n - 1) * HEIGHT, (n - 1) * HEIGHT), squeeze=False)\n",
        "\n",
        "    for i in range(len(vars_no_target)):\n",
        "        var1: str = vars_no_target[i]\n",
        "        for j in range(i + 1, len(vars_no_target)):\n",
        "            var2: str = vars_no_target[j]\n",
        "            plot_multi_scatters_chart(data, var1, var2, target, ax=axs[i, j - 1])\n",
        "\n",
        "    output_path = f\"images/sparsity_per_class/{file_tag}_sparsity_per_class_study.png\"\n",
        "    savefig(output_path)\n",
        "    close()\n",
        "    print(f\"   ✓ Saved per-class study: {output_path}\")\n",
        "\n",
        "print(f\"   ✓ Completed {file_tag.upper()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"SPARSITY PROFILING COMPLETE!\")"
      ],
      "metadata": {
        "id": "mzqicj1_Rqfe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}