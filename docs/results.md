# Performance Results - Lab 1 Baseline Models

## Overview

This report presents the baseline performance of five classification models (Naive Bayes, K-Nearest Neighbors, Decision Tree, Logistic Regression, and Multi-Layer Perceptron) evaluated across four datasets: Traffic, Accidents, Economic Indicators, and Flights. All models were trained and tested on **raw, unscaled data** to establish baseline performance metrics.

---

## Best Model Summary

| Dataset | Best Model | Accuracy | Precision | Recall | Notes |
|---------|------------|----------|-----------|--------|-------|
| **Traffic** | Decision Tree | 0.950 | 0.922 | 0.919 | Excellent performance on 4-class problem |
| **Accidents** | Decision Tree | 0.828 | 0.867 | 0.807 | Best of available models |
| **Economic** | Logistic Regression | 0.373 | 0.174 | 0.250 | All models struggle (4-class GDP prediction) |
| **Flights** | Decision Tree | 0.941 | 0.932 | 0.890 | Binary delay prediction |

---

## Dataset Analysis

### 1. Traffic Dataset (5,953 records ‚Üí 4,166 train / 1,787 test)

**Task:** Predict traffic situation (4 classes: low, normal, heavy, high)

**Results:**
- Decision Tree: **95.0% accuracy** ‚≠ê Best performer
- MLP: 94.4% accuracy
- KNN: 92.8% accuracy  
- LogReg: 83.3% accuracy
- Naive Bayes: 82.8% accuracy

**Analysis:** The high performance across most models (>90%) suggests clear patterns in the data. Decision Trees excel by creating straightforward rules based on vehicle counts. The strong baseline indicates the task has well-defined class boundaries, making it suitable for tree-based approaches.

**Best Hyperparameters (Decision Tree):**
- Criterion: Gini
- Max Depth: 15
- Random State: 42

---

### 2. Accidents Dataset (209,306 records ‚Üí 146,514 train / 62,792 test)

**Task:** Predict crash type (2 classes: "NO INJURY / DRIVE AWAY" vs "INJURY AND / OR TOW DUE TO CRASH")

**Results:**
- Decision Tree: **82.8% accuracy** ‚≠ê Best performer
- Naive Bayes: 82.1% accuracy
- KNN: *Skipped* (computationally prohibitive on 146k rows)
- LogReg: *Skipped* (slow convergence on unscaled data)
- MLP: *Skipped* (requires feature scaling)

**Analysis:** This is the **most realistic baseline** in the lab. With ~83% accuracy on a binary classification problem, the model shows genuine predictive power (baseline of always predicting majority class would give ~56%). The similar performance between Decision Tree and Naive Bayes suggests moderate class separability without obvious decision boundaries.

**Computational Note:** The large dataset size (146k training samples) made KNN, LogReg, and MLP impractical without preprocessing. KNN requires O(n¬≤) distance computations, while iterative models (LogReg, MLP) converge slowly on unscaled features.

**Best Hyperparameters (Decision Tree):**
- Criterion: Entropy
- Max Depth: 6
- Random State: 42

---

### 3. Economic Dataset (501 records ‚Üí 350 train / 150 test)

**Task:** Predict GDP Growth Category (4 classes: High, Medium, Low, Negative)

**Results:**
- Logistic Regression: **37.3% accuracy** ‚≠ê Best performer
- Naive Bayes: 36.7% accuracy
- Decision Tree: 34.7% accuracy
- MLP: 32.0% accuracy
- KNN: 24.0% accuracy

**Analysis:** All models perform **poorly** (barely above random guessing at 25% for 4 classes). This indicates:
1. **Insufficient features** - Only 5 economic indicators may not capture GDP dynamics
2. **Class overlap** - Economic categories likely have fuzzy boundaries
3. **Small sample size** - 350 training samples across 10 countries is limited
4. **Complex relationships** - Economic prediction requires temporal patterns, not just snapshots

This dataset would benefit from:
- Time-series features (lags, trends)
- Country-specific encoding
- More economic indicators
- Feature engineering (ratios, changes over time)

**Best Hyperparameters (Logistic Regression):**
- Penalty: L2 (Ridge)
- Solver: liblinear
- Max Iterations: 50

---

### 4. Flights Dataset (394,700 records ‚Üí 276,288 train / 118,410 test)

**Task:** Predict arrival delay >15 minutes (2 classes: 0=on-time, 1=delayed)

**Results:**
- Decision Tree: **94.1% accuracy** ‚≠ê Best performer
- Naive Bayes: 93.4% accuracy
- KNN: *Skipped* (computationally prohibitive)
- LogReg: *Skipped* (slow on large unscaled data)
- MLP: *Skipped* (requires feature scaling)

**Analysis:** The high accuracy (>93%) on this large binary classification task is impressive. However, it's important to note:
- **Class imbalance:** ~78% of flights are on-time, so baseline is already high
- **Fixed features:** Using only pre-departure information (no data leakage)
- **Scale challenges:** 276k samples √ó 15 features makes distance-based and iterative methods impractical

Decision Tree succeeded where other models couldn't due to:
1. No need for feature scaling
2. Non-iterative training (greedy splits)
3. Efficient handling of high-dimensional data
4. Good performance on imbalanced datasets with proper depth tuning

**Best Hyperparameters (Decision Tree):**
- Criterion: Entropy
- Max Depth: 15
- Random State: 42

---

## Model Comparison: Decision Trees vs Others

### Why Decision Trees Dominated These Baselines

**1. No Feature Scaling Required**
- Decision Trees split on threshold values regardless of scale
- MLP/LogReg/KNN all suffer from unscaled features with different ranges
- Example: Flight distance (100-3000 miles) vs DayOfWeek (1-7) - Trees handle naturally

**2. Computational Efficiency**
- **Training:** O(n log n) greedy algorithm vs iterative optimization
- **Prediction:** O(log n) tree traversal vs O(n) for KNN or matrix operations for MLP
- This made Trees the only model that completed on large datasets

**3. Handling of Mixed Feature Distributions**
- No assumptions about feature distributions
- Works with discrete, continuous, and categorical data equally
- Robust to outliers

**4. Natural Feature Selection**
- Trees automatically identify most informative features
- Less relevant features ignored in splits
- No manual feature engineering needed

### When Other Models Would Excel

This lab used **deliberately unfavorable conditions** (raw, unscaled data) to establish baselines. With preprocessing:

**MLP would improve significantly if:**
- Features were standardized (z-score normalization)
- More training epochs with learning rate scheduling
- Proper architecture tuning (hidden layers, neurons)
- ‚Üí Expected +5-10% accuracy boost

**KNN would be competitive if:**
- Features were scaled to [0,1] range
- Dimensionality reduction applied (PCA)
- Sample size reduced or GPU acceleration used
- ‚Üí Could match Decision Trees on Traffic/Economic

**Logistic Regression would excel if:**
- Features normalized and polynomial terms added
- Proper solver selected (saga for large data)
- Regularization tuned
- ‚Üí Best for interpretability requirements

---

## Computational Performance Summary

| Model | Traffic (4k) | Accidents (146k) | Economic (350) | Flights (276k) |
|-------|--------------|------------------|----------------|----------------|
| **Naive Bayes** | ‚úÖ Fast | ‚úÖ Fast | ‚úÖ Fast | ‚úÖ Fast |
| **KNN** | ‚úÖ ~30s | ‚ùå Skipped | ‚úÖ Fast | ‚ùå Skipped |
| **Decision Tree** | ‚úÖ Fast | ‚úÖ ~45s | ‚úÖ Fast | ‚úÖ ~60s |
| **LogReg** | ‚úÖ ~20s | ‚ùå Skipped | ‚úÖ Fast | ‚ùå Skipped |
| **MLP** | ‚úÖ ~40s | ‚ùå Skipped | ‚úÖ ~15s | ‚ùå Skipped |

**Key Takeaway:** Only Decision Trees and Naive Bayes scaled to all datasets without preprocessing.

---

## Missing Values Explanation

**Why KNN/LogReg/MLP show 0.0 for Accidents and Flights:**

These models were **intentionally skipped** due to computational constraints:

1. **KNN:** Distance calculations require O(n¬≤) operations. With 146k-276k training samples, this means billions of distance computations at prediction time. Without GPU acceleration or data sampling, training would take hours.

2. **Logistic Regression:** Uses iterative optimization (gradient descent). On unscaled features with large sample sizes, convergence is extremely slow. Each iteration processes all 276k samples, and hundreds of iterations are needed.

3. **MLP:** Combines both issues - needs feature scaling AND iterative training through backpropagation. With raw features of different scales, gradients become unstable, requiring thousands of epochs.

**Real-world solution:** These models become viable with:
- Feature scaling (StandardScaler)
- Dimensionality reduction (PCA)
- Mini-batch training
- GPU acceleration
- Or accepting longer training times (hours instead of minutes)

---

## Key Insights

### 1. Dataset Difficulty Ranking
1. **Easiest:** Traffic (95% accuracy) - Clear patterns
2. **Moderate:** Flights (94% accuracy) - Large but clean
3. **Moderate:** Accidents (83% accuracy) - Realistic performance
4. **Hardest:** Economic (37% accuracy) - Requires feature engineering

### 2. Raw Data Limitations
This lab intentionally used unprocessed data to show:
- ‚úÖ Decision Trees are robust to raw data
- ‚ùå Neural networks NEED preprocessing
- ‚ùå Distance-based methods NEED scaling
- ‚ö†Ô∏è Computational cost varies dramatically

### 3. Class Imbalance Impact
- **Traffic:** Balanced enough (60% normal)
- **Accidents:** Imbalanced (56% no injury) - affects precision/recall
- **Economic:** Balanced by design
- **Flights:** Imbalanced (78% on-time) - high accuracy partly artificial

---

## Recommendations for Future Work

### Immediate Improvements (Lab 2)

1. **Feature Scaling**
   ```python
   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   X_train_scaled = scaler.fit_transform(X_train)
   ```
   Expected impact: +5-15% accuracy on MLP/KNN

2. **Handle Class Imbalance**
   ```python
   from imblearn.over_sampling import SMOTE
   ```
   Expected impact: Better precision/recall balance

3. **Feature Engineering (Economic)**
   - Add temporal features
   - Create interaction terms
   - Country-specific indicators

4. **Hyperparameter Optimization**
   - Grid search with cross-validation
   - Currently using "reasonable defaults"

### Advanced Techniques (Lab 3+)

- Ensemble methods (Random Forest, XGBoost)
- Deep learning with proper architecture
- Feature selection (recursive elimination)
- Cross-validation for robust estimates
- ROC-AUC for imbalanced problems

---

## Conclusion

This baseline establishes that:

‚úÖ **Decision Trees are the clear winner** on raw data (3 of 4 datasets)  
‚úÖ **Accidents dataset provides the most realistic benchmark** (~83%)  
‚ö†Ô∏è **Computational cost is a real constraint** without preprocessing  
‚ö†Ô∏è **Economic dataset needs redesign** or feature engineering  
üìä **Preprocessing will unlock MLP/KNN potential** (expected in Lab 2)

The results demonstrate fundamental ML principles:
- Model selection depends on data characteristics
- Preprocessing is not optional for many algorithms
- Computational efficiency matters at scale
- Baseline performance guides improvement efforts

**Next Steps:** Apply feature scaling and engineering to see which models improve most dramatically.

---

## Appendix: Baseline Metrics

**Dummy Classifier Performance (Always Predict Majority Class):**
- Traffic: 60.7% (would always predict "normal")
- Accidents: 56.0% (would always predict "no injury")
- Economic: 25.0% (random for 4 classes)
- Flights: 78.4% (would always predict "on-time")

**Our Models Beat These Baselines By:**
- Traffic: +34.3% (Decision Tree 95.0% vs 60.7%)
- Accidents: +26.8% (Decision Tree 82.8% vs 56.0%)
- Economic: +12.3% (LogReg 37.3% vs 25.0%)
- Flights: +15.7% (Decision Tree 94.1% vs 78.4%)

This confirms all models learned meaningful patterns beyond simple majority-class prediction.
